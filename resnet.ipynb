{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, transforms\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:02:43.665308Z","iopub.execute_input":"2025-08-27T06:02:43.665482Z","iopub.status.idle":"2025-08-27T06:02:51.473469Z","shell.execute_reply.started":"2025-08-27T06:02:43.665466Z","shell.execute_reply":"2025-08-27T06:02:51.472923Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform = transforms.ToTensor()\ntrainset = torchvision.datasets.CIFAR10(root='./cifardata', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=50000, shuffle=False)\n\ndataiter = iter(trainloader)\nimages, labels = next(dataiter)\nmean = images.mean(dim=[0, 2, 3])\nstd = images.std(dim=[0, 2, 3])\nprint(\"Mean:\", mean)\nprint(\"Std:\", std)\n\nnormalize = transforms.Normalize(mean=mean.tolist(),\n                                 std=std.tolist())\n\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.CIFAR10(root='./cifardata', train=True, transform=transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomCrop(32, padding=4),\n        transforms.ToTensor(),\n        normalize,\n    ]), download=False),\n    batch_size=128, shuffle=True, num_workers=4, pin_memory=True\n)\n\nval_loader = torch.utils.data.DataLoader(\n    datasets.CIFAR10(root='./cifardata', train=False, transform=transforms.Compose([\n        transforms.ToTensor(),\n        normalize,\n    ])),\n    batch_size=128, shuffle=False, num_workers=4, pin_memory=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:02:51.474968Z","iopub.execute_input":"2025-08-27T06:02:51.475338Z","iopub.status.idle":"2025-08-27T06:03:18.777600Z","shell.execute_reply.started":"2025-08-27T06:02:51.475319Z","shell.execute_reply":"2025-08-27T06:03:18.777033Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. ResNet50 (bottleneck)\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        self.conv3 = nn.Conv2d(out_channels, out_channels * 4, kernel_size=1, stride=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(out_channels * 4)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_channels != out_channels * 4:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels * 4, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels * 4)\n            )\n\n    def forward(self, x):\n        shortcut = self.shortcut(x)\n\n        out = self.relu(self.bn1(self.conv1(x)))\n        out = self.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n\n        out += shortcut\n        out = self.relu(out)\n        return out\n\nclass MyResNet50(nn.Module):\n    def __init__(self, num_classes=10):  # CIFAR-10 có 10 classes\n        super(MyResNet50, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.Identity()  # bỏ maxpool\n\n        self.stage1 = self._make_stage(64, 64, stride=1, num_blocks=3)\n        self.stage2 = self._make_stage(256, 128, stride=2, num_blocks=4)\n        self.stage3 = self._make_stage(512, 256, stride=2, num_blocks=6)\n        self.stage4 = self._make_stage(1024, 512, stride=2, num_blocks=3)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(2048, num_classes)\n\n    def _make_stage(self, in_channels, out_channels, stride, num_blocks):\n        layers = [ResidualBlock(in_channels, out_channels, stride)]\n        for _ in range(1, num_blocks):\n            layers.append(ResidualBlock(out_channels * 4, out_channels, stride=1))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.relu(self.bn1(self.conv1(x)))\n        out = self.maxpool(out)\n\n        out = self.stage1(out)\n        out = self.stage2(out)\n        out = self.stage3(out)\n        out = self.stage4(out)\n\n        out = self.avgpool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc(out)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:03:18.778297Z","iopub.execute_input":"2025-08-27T06:03:18.778480Z","iopub.status.idle":"2025-08-27T06:03:18.789534Z","shell.execute_reply.started":"2025-08-27T06:03:18.778466Z","shell.execute_reply":"2025-08-27T06:03:18.788854Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n    expansion = 1  \n\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n                               stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n                               stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1,\n                          stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n\n    def forward(self, x):\n        shortcut = self.shortcut(x)\n\n        out = self.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n\n        out += shortcut\n        out = self.relu(out)\n        return out\n\n\nclass MyResNet18(nn.Module):\n    def __init__(self, num_classes=10): \n        super(MyResNet18, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.Identity()  \n\n        self.stage1 = self._make_stage(64, 64, num_blocks=2, stride=1)\n        self.stage2 = self._make_stage(64, 128, num_blocks=2, stride=2)\n        self.stage3 = self._make_stage(128, 256, num_blocks=2, stride=2)\n        self.stage4 = self._make_stage(256, 512, num_blocks=2, stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512, num_classes)\n\n    def _make_stage(self, in_channels, out_channels, num_blocks, stride):\n        layers = [BasicBlock(in_channels, out_channels, stride)]\n        for _ in range(1, num_blocks):\n            layers.append(BasicBlock(out_channels, out_channels, stride=1))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.relu(self.bn1(self.conv1(x)))\n        out = self.maxpool(out)\n\n        out = self.stage1(out)\n        out = self.stage2(out)\n        out = self.stage3(out)\n        out = self.stage4(out)\n\n        out = self.avgpool(out)\n        out = torch.flatten(out, 1)\n        out = self.fc(out)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:03:18.790316Z","iopub.execute_input":"2025-08-27T06:03:18.790916Z","iopub.status.idle":"2025-08-27T06:03:18.843557Z","shell.execute_reply.started":"2025-08-27T06:03:18.790889Z","shell.execute_reply":"2025-08-27T06:03:18.842732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = MyResNet18(num_classes=10).to(device) #ResNet18\n# model = MyResNet50(num_classes=10).to(device)\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n\ntrain_losses, train_accuracies = [], []\ntest_losses, test_accuracies = [], []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:03:18.844446Z","iopub.execute_input":"2025-08-27T06:03:18.844713Z","iopub.status.idle":"2025-08-27T06:03:19.157908Z","shell.execute_reply.started":"2025-08-27T06:03:18.844691Z","shell.execute_reply":"2025-08-27T06:03:19.157272Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for epoch in range(40):\n    # ---- training ----\n    model.train()\n    train_loss, correct, total = 0, 0, 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        outputs = model(images)\n        loss = loss_fn(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item() * images.size(0)\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\n    train_loss /= total\n    train_acc = 100. * correct / total\n\n    # ---- evaluation ----\n    model.eval()\n    test_loss, correct, total = 0, 0, 0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = loss_fn(outputs, labels)\n\n            test_loss += loss.item() * images.size(0)\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n    test_loss /= total\n    test_acc = 100. * correct / total\n    scheduler.step()\n\n    print(f\"Epoch {epoch+1:03d} | \"\n          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n          f\"Val Loss: {test_loss:.4f}, Val Acc: {test_acc:.2f}%\")\n\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n    test_losses.append(test_loss)\n    test_accuracies.append(test_acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:03:19.158585Z","iopub.execute_input":"2025-08-27T06:03:19.158805Z","iopub.status.idle":"2025-08-27T06:20:31.543852Z","shell.execute_reply.started":"2025-08-27T06:03:19.158786Z","shell.execute_reply":"2025-08-27T06:20:31.542957Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs = range(1, len(train_losses) + 1)\n\n# Vẽ loss\nplt.figure()\nplt.plot(epochs, train_losses, label='Train Loss')\nplt.plot(epochs, test_losses, label='Test Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Loss per Epoch')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Vẽ accuracy\nplt.figure()\nplt.plot(epochs, train_accuracies, label='Train Accuracy')\nplt.plot(epochs, test_accuracies, label='Test Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.title('Accuracy per Epoch')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T06:20:31.546106Z","iopub.execute_input":"2025-08-27T06:20:31.546420Z","iopub.status.idle":"2025-08-27T06:20:31.952675Z","shell.execute_reply.started":"2025-08-27T06:20:31.546395Z","shell.execute_reply":"2025-08-27T06:20:31.951995Z"}},"outputs":[],"execution_count":null}]}